{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.12 ('swin-det': conda)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n swin-det ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.12 ('swin-det': conda)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n swin-det ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "basefolder_pre = '/home/zikaixiao/zikai'\n",
    "basefolder = 'baseline/'\n",
    "# fpath = '/home/songshangliu/fl_longtailed/fl_framework_lss/baseline/fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "# fpath = '/home/songshangliu/fl_longtailed/fl_framework_lss/baseline/fl_LP_0.1_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "\n",
    "\n",
    "\n",
    "def process_floats(l):\n",
    "  newlist = []\n",
    "  for f in l:\n",
    "    # d = format(f,'.4f')\n",
    "    d = f[:6]\n",
    "    d = float(d)\n",
    "    newlist.append(d)\n",
    "  return newlist\n",
    "# bestacc_file  = open('bestacc.txt','w')\n",
    "\n",
    "\n",
    "basefolder = os.path.join(basefolder_pre,'fl_framework_lss', 'temp')\n",
    "filelist = os.listdir(basefolder)\n",
    "print(filelist)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "  fpath = os.path.join(basefolder,file)\n",
    "  f = open(fpath,'r')\n",
    "  acclist = []\n",
    "  for line in f.readlines():\n",
    "    acc = line.split()[4]\n",
    "    acclist.append(acc)\n",
    "  acclist = process_floats(acclist)\n",
    "  if len(acclist)<400:\n",
    "    continue\n",
    "  \n",
    "\n",
    "  bestacc = max(acclist)\n",
    "  # bestacc_file.write(file)\n",
    "  # bestacc_file.write('length: '+ str(len(acclist))+'    '+ 'Best Acc'+ str(bestacc))\n",
    "  # bestacc_file.flush()\n",
    "  print(file)\n",
    "  print('length: '+ str(len(acclist))+'    '+ 'Best Acc '+ str(bestacc)+'\\n')\n",
    "  f.close()\n",
    "\n",
    "# bestacc_file.close()\n",
    "# acclist = []\n",
    "# accfile = open(fpath)\n",
    "# for line in accfile.readlines():\n",
    "#     acc = line.split()[4]\n",
    "#     acclist.append(acc)\n",
    "# # print(acclist)\n",
    "# acclist = process_floats(acclist)\n",
    "# # print(acclist)\n",
    "# xaxis = range(500)\n",
    "# plt.plot(xaxis,acclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/home/songshangliu/fl_longtailed/fl_framework_lss/baseline/fl_LP_0.1_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "def process_floats(l):\n",
    "  newlist = []\n",
    "  for f in l:\n",
    "    # d = format(f,'.4f')\n",
    "    d = f[:6]\n",
    "    d = float(d)\n",
    "    newlist.append(d)\n",
    "  return newlist\n",
    "acclist = []\n",
    "accfile = open(fpath)\n",
    "for line in accfile.readlines():\n",
    "    acc = line.split()[4]\n",
    "    acclist.append(acc)\n",
    "# print(acclist)\n",
    "acclist = process_floats(acclist)\n",
    "# print(acclist)\n",
    "xaxis = range(500)\n",
    "plt.plot(xaxis,acclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/home/songshangliu/fedper_new/baseline/fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter200_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "#fedper\n",
    "def process_floats(l):\n",
    "  newlist = []\n",
    "  for f in l:\n",
    "    # d = format(f,'.4f')\n",
    "    d = f[:6]\n",
    "    d = float(d)\n",
    "    newlist.append(d)\n",
    "  return newlist\n",
    "acclist = []\n",
    "accfile = open(fpath)\n",
    "for line in accfile.readlines():\n",
    "    acc = line.split()[4]\n",
    "    acclist.append(acc)\n",
    "# print(acclist)\n",
    "acclist = process_floats(acclist)\n",
    "# print(acclist)\n",
    "xaxis = range(200)\n",
    "plt.plot(xaxis,acclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from options import args_parser\n",
    "from util.update_baseline import LocalUpdate, globaltest\n",
    "from util.fedavg import FedAvg, FedAvg_noniid\n",
    "# from util.util import add_noise\n",
    "from util.dataset import get_dataset\n",
    "from model.build_model import build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import client\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from yaml import DirectiveToken\n",
    "from util.sampling import iid_sampling, non_iid_dirichlet_sampling\n",
    "import torch.utils\n",
    "from util.imbalance_cifar import IMBALANCECIFAR10\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/mnt/songshang/cifar_lt/'\n",
    "# args.num_classes = 10\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "dataset_train = IMBALANCECIFAR10(data_path, imb_factor=0.002,train=True, download=True, transform=trans_train)\n",
    "# dataset_train = datasets.CIFAR10(data_path, train=True, download=True, transform=trans_train)\n",
    "n_train = len(dataset_train)\n",
    "y_train = np.array(dataset_train.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_users = non_iid_dirichlet_sampling(y_train, 10,1,40,1,alpha_dirichlet=1 )\n",
    "dict_users = iid_sampling(n_train, 40, 1)\n",
    "clients_sizes= [len(dict_users[i]) for i in range(40)]\n",
    "alist = np.array([[np.sum(y_train[list(dict_users[i])]==j) for j in range(10)] for i in range(len(clients_sizes))])\n",
    "print(alist)\n",
    "print(alist.sum(0))\n",
    "print(alist.sum(1))\n",
    "global_list = alist.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "res = alist.sum(0)\n",
    "\n",
    "frame1 = pd.DataFrame(res)\n",
    "frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "res = [4000 for i in range(7)]\n",
    "frame1 = pd.DataFrame(res)\n",
    "frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = [int(4000+1000*(2*np.random.random()-1)) for i in range(10)]\n",
    "frame1 = pd.DataFrame(res)\n",
    "frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "\n",
    "f_label = open(\"cifar10_NL_0.6_LB_0.5_Iter_5_1_Rnd_500_450_ep_5_5_Frac_0.01_0.10_LR_0.030_ReR_0.5_ConT_0.5_ClT_0.1_Beta_5.0_Seed_1_IID_FT_CORR_Mix_1.0_lable.txt\")\n",
    "lines = f_label.readlines()\n",
    "f_label.close()\n",
    "f_dict = open(\"dict.txt\")\n",
    "lines2 = f_dict.readlines()\n",
    "fig, axes = plt.subplots(1, 5, sharex=False,sharey=True, figsize=(18, 3), dpi=600)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = eval(lines2[i].replace(\"\\n\",\"\"))\n",
    "    y_true = np.array(eval(lines[0].replace(\"\\n\",\"\")))[idx]\n",
    "    y_noisy = np.array(eval(lines[10].replace(\"\\n\",\"\")))[idx]\n",
    "    conf_matrix = confusion_matrix(y_true, y_noisy)\n",
    "#     fig = plt.figure(figsize=(6, 6))\n",
    "#     ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(conf_matrix, cmap=plt.cm.hot_r)\n",
    "#     ax.set_ylabel(\"True label\", fontsize=12)\n",
    "#     ax.set_xlabel(\"Given label\", fontsize=12)\n",
    "#     title = \"Client \" + str(i+1)\n",
    "#     ax.set_title(title, fontsize=14)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.3)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "data_path = '/mnt/songshang/cifar_lt/'\n",
    "# args.num_classes = 10\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "dataset_train = IMBALANCECIFAR10(data_path, imb_factor=0.01,train=True, download=True, transform=trans_train)\n",
    "# dataset_train = datasets.CIFAR10(data_path, train=True, download=True, transform=trans_train)\n",
    "n_train = len(dataset_train)\n",
    "y_train = np.array(dataset_train.targets)\n",
    "\n",
    "num_users = 20\n",
    "dict_users = iid_sampling(n_train, num_users, 1)\n",
    "clients_sizes= [len(dict_users[i]) for i in range(num_users)]\n",
    "alist = np.array([[np.sum(y_train[list(dict_users[i])]==j) for j in range(10)] for i in range(len(clients_sizes))])\n",
    "print(alist)\n",
    "print(alist.sum(0))\n",
    "print(alist.sum(1))\n",
    "global_list = alist.sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(dpi=290)\n",
    "sns_plot = sns.heatmap(alist,cmap='Reds',yticklabels=5)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Client')\n",
    "plt.show()\n",
    "#copper_r, summer_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1,ax2) = plt.subplots(nrows=2,sharex=True)\n",
    "fig = plt.figure(dpi=290)\n",
    "ax1=sns.heatmap([global_list],cmap='Reds')\n",
    "# ax1.imshow([global_list],cmap='Reds')\n",
    "# ax2.imshow(alist,cmap='RdPu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "data_path = '/mnt/songshang/cifar_lt/'\n",
    "# args.num_classes = 10\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "dataset_train = IMBALANCECIFAR10(data_path, imb_factor=0.2,train=True, download=True, transform=trans_train)\n",
    "# dataset_train = datasets.CIFAR10(data_path, train=True, download=True, transform=trans_train)\n",
    "n_train = len(dataset_train)\n",
    "y_train = np.array(dataset_train.targets)\n",
    "\n",
    "num_users = 20\n",
    "alpha = 0.3\n",
    "dict_users = non_iid_dirichlet_sampling(y_train, 10, 1,num_users, 1, alpha)\n",
    "clients_sizes= [len(dict_users[i]) for i in range(num_users)]\n",
    "alist = np.array([[np.sum(y_train[list(dict_users[i])]==j) for j in range(10)] for i in range(len(clients_sizes))])\n",
    "print(alist)\n",
    "print(alist.sum(0))\n",
    "print(alist.sum(1))\n",
    "global_list = alist.sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(dpi=290)\n",
    "sns_plot = sns.heatmap(alist,cmap='Reds',yticklabels=5)\n",
    "# sns_plot = sns.heatmap(alist,cmap='Reds',robust=True,yticklabels=5)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Client')\n",
    "plt.show()\n",
    "#copper_r, summer_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=2,sharex=True)\n",
    "ax1=sns.heatmap([global_list],cmap='Reds')\n",
    "ax1.imshow([global_list],cmap='Reds')\n",
    "# ax2.imshow(alist,cmap='RdPu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "data_path = '/mnt/songshang/cifar_lt/'\n",
    "# args.num_classes = 10\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])],\n",
    ")\n",
    "dataset_train = datasets.CIFAR10(data_path,train=True, download=True, transform=trans_train)\n",
    "# dataset_train = datasets.CIFAR10(data_path, train=True, download=True, transform=trans_train)\n",
    "n_train = len(dataset_train)\n",
    "y_train = np.array(dataset_train.targets)\n",
    "\n",
    "num_users = 20\n",
    "dict_users = iid_sampling(n_train, num_users, 1)\n",
    "for i in range(num_users):\n",
    "        # create a longtailed distribution in client i\n",
    "        cls_num=10\n",
    "        client_size = len(dict_users[i])\n",
    "        # print(client_size)\n",
    "        img_max = client_size/ cls_num\n",
    "        lt_sizes = []\n",
    "        for cls_idx in range(cls_num):\n",
    "            num = img_max * (0.01**(cls_idx / (cls_num - 1.0)))\n",
    "            lt_sizes.append(int(num))\n",
    "        \n",
    "        head = i%cls_num #decide the head class in longtailed distribution\n",
    "        for j in range(10): # for each class\n",
    "            cur_cls = (head+j)%10   #current class idx\n",
    "            target_cls_size = lt_sizes[j]\n",
    "            labellist = y_train[list(dict_users[i])]==cur_cls\n",
    "            cur_cls_size = np.sum(labellist)\n",
    "            indices= []\n",
    "            for (idx,v) in enumerate(labellist):\n",
    "                if v==True:\n",
    "                    indices.append(list(dict_users[i])[idx])\n",
    "           \n",
    "            assert len(indices)==cur_cls_size\n",
    "            for n in range(len(indices)):\n",
    "                assert y_train[indices[n]]==cur_cls\n",
    "            if target_cls_size== cur_cls_size or target_cls_size>cur_cls_size:\n",
    "                print('the current class doesnt need dropout')\n",
    "                continue\n",
    "            elif target_cls_size<cur_cls_size:\n",
    "                clientlist = list(dict_users[i])\n",
    "                cnt = cur_cls_size-target_cls_size\n",
    "                for m in range(cnt):\n",
    "                    clientlist.remove(indices[m])\n",
    "                    # pop one instance of class j from dict_user[i]\n",
    "                dict_users[i] = set(clientlist)\n",
    "        \n",
    "alist = np.array([[np.sum(y_train[list(dict_users[i])]==j) for j in range(10)] for i in range(num_users)])\n",
    "print(alist)\n",
    "\n",
    "\n",
    "print(alist.sum(0))\n",
    "print(alist.sum(1))\n",
    "global_list = alist.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(dpi=290)\n",
    "sns_plot = sns.heatmap(alist,cmap='Reds',yticklabels=5)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Client')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=2,sharex=True,)\n",
    "ax1=sns.heatmap([global_list],cmap='Reds',vmin=0,vmax=1)\n",
    "ax1.imshow([global_list],cmap='Reds')\n",
    "# ax2.imshow(alist,cmap='RdPu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.1.txt', 'fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.02.txt', 'fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.01.txt', 'global_fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.02.txt', 'global_fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.1.txt', 'global_fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.01.txt', 'fl_acc_cifar10_resnet18_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.02.txt', 'fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.1.txt', 'fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet0.5_IF0.01.txt']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69094/4249885778.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mbestacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_acclist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0;31m# bestacc_file.write(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# bestacc_file.write('length: '+ str(len(acclist))+'    '+ 'Best Acc'+ str(bestacc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "basefolder_pre = '/home/songshangliu/'\n",
    "basefolder = 'baseline3/'\n",
    "# fpath = '/home/songshangliu/fl_longtailed/fl_framework_lss/baseline/fl_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "# fpath = '/home/songshangliu/fl_longtailed/fl_framework_lss/baseline/fl_LP_0.1_acc_cifar10_resnet18_cons_frac0.2_iidTrue_iter500_ep5_lr0.03_N40_10_seed1_p1_dirichlet10_IF0.01.txt'\n",
    "\n",
    "\n",
    "\n",
    "def process_floats(l):\n",
    "  newlist = []\n",
    "  for f in l:\n",
    "    # d = format(f,'.4f')\n",
    "    d = f[:6]\n",
    "    d = float(d)\n",
    "    newlist.append(d)\n",
    "  return newlist\n",
    "# bestacc_file  = open('bestacc.txt','w')\n",
    "\n",
    "\n",
    "basefolder = os.path.join(basefolder_pre,'fl_longtailed','fl_framework_lss', 'baseline3')\n",
    "filelist = os.listdir(basefolder)\n",
    "print(filelist)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "  fpath = os.path.join(basefolder,file)\n",
    "  f = open(fpath,'r')\n",
    "  local_acclist = []\n",
    "  global_acclist = []\n",
    "  for line in f.readlines():\n",
    "    row = line.split()\n",
    "    acc = row[-1]\n",
    "    if len(row)==6:\n",
    "        global_acclist.append(acc)\n",
    "    elif len(row)==7:\n",
    "        global_acclist.append(acc)\n",
    "    \n",
    "  global_acclist = process_floats(global_acclist)\n",
    "  local_acclist = process_floats(local_acclist)\n",
    "  \n",
    "\n",
    "  bestacc = max(local_acclist)\n",
    "  # bestacc_file.write(file)\n",
    "  # bestacc_file.write('length: '+ str(len(acclist))+'    '+ 'Best Acc'+ str(bestacc))\n",
    "  # bestacc_file.flush()\n",
    "  print(file)\n",
    "  print('length: '+ str(len(acclist))+'    '+ 'Best Acc '+ str(bestacc)+'\\n')\n",
    "  f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('swin-det': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b24a3e7f35a6a362f4cfec5e803e191812bb8a326c35322ee0f50035ff321d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
